"use strict";(self.webpackChunkictf_docs=self.webpackChunkictf_docs||[]).push([[7158],{862:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>i,contentTitle:()=>o,default:()=>p,frontMatter:()=>a,metadata:()=>l,toc:()=>c});var n=r(4848),s=r(8453);const a={},o=void 0,l={id:"writeups/pixel-mirage-2/attack_util.py",title:"attack_util.py",description:"",source:"@site/docs/writeups/pixel-mirage-2/attack_util.py.md",sourceDirName:"writeups/pixel-mirage-2",slug:"/writeups/pixel-mirage-2/attack_util.py",permalink:"/ictf-docs/writeups/pixel-mirage-2/attack_util.py",draft:!1,unlisted:!1,editUrl:"https://github.com/ucsb-seclab/ictf-docs/tree/main/docs/writeups/pixel-mirage-2/attack_util.py.md",tags:[],version:"current",frontMatter:{},sidebar:"writeups",previous:{title:"Pixel Mirage (part 2)",permalink:"/ictf-docs/writeups/pixel-mirage-2/"},next:{title:"data_util.py",permalink:"/ictf-docs/writeups/pixel-mirage-2/data_util.py"}},i={},c=[];function d(e){const t={code:"code",pre:"pre",...(0,s.R)(),...e.components};return(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:"import numpy as np\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\n\r\n### PGD Attack\r\nclass PGDAttack():\r\n    def __init__(self, attack_step=10, eps=8 / 255, alpha=2 / 255, loss_type='ce', targeted=True, \r\n                 num_classes=10,device='cuda:0'):\r\n        '''\r\n        attack_step: number of PGD iterations\r\n        eps: attack budget\r\n        alpha: PGD attack step size\r\n        '''\r\n        ### Your code here\r\n        self.attack_step = attack_step\r\n        self.eps = eps\r\n        self.alpha = alpha\r\n        self.loss_func = self.ce_loss if loss_type == 'ce' else self.cw_loss\r\n        self.targeted = targeted\r\n        self.num_classes = num_classes\r\n        #added device, so that in the loss functions, the calculations won't cause errors (can call .to() to move tensor to device)\r\n        self.device = device\r\n        ### Your code ends\r\n\r\n    def ce_loss(self, logits, y):\r\n        ### Your code here\r\n        \r\n        loss = 0.0\r\n        # convert y to a tensor of [batch size, num_classes]. for each photo (each element in the tensor array), it's a tensor such that it's 0 for classes other than the true class, and 1 for the true class.\r\n        y_transformed = torch.eye(self.num_classes)[y.view(-1)].float().to(self.device)\r\n        # print(y_transformed)\r\n        # implement CE loss function in slide. Since photos come in batch of 64, get the mean to convert loss to scalar.\r\n        # note: log_softmax gets the log of prediction probability \r\n        loss = -torch.mean(torch.sum(y_transformed * torch.nn.functional.log_softmax(logits,dim=1), dim=1))\r\n        return loss\r\n        ### Your code ends\r\n\r\n    def cw_loss(self, logits, y):\r\n        ### Your code here\r\n        #assume tao is 0\r\n        t = 0\r\n        if self.targeted:\r\n            # target is class 1\r\n            target_labels = torch.ones_like(y)\r\n            target_transformed = torch.eye(self.num_classes)[target_labels.view(-1)].float().to(self.device)\r\n\r\n            # get the largest logit that is not the target\r\n            largest, _ = torch.max((1-target_transformed)*logits, dim=1) \r\n            # get the target label logit. Select out ones that correspond to the target label\r\n            target = torch.masked_select(logits, target_transformed.bool()) \r\n\r\n            # max among the difference between larget logit label and target, and -tao\r\n            # use sum to convert to a scalar for a batch\r\n            loss = -torch.clamp((largest-target),min=-t).sum()\r\n\r\n            return loss\r\n        else:\r\n            y_transformed = torch.eye(self.num_classes)[y.view(-1)].float().to(self.device)\r\n            # print(1-y_transformed)\r\n            # get the second largest logit that is not the true label\r\n            second_largest, _ = torch.max((1-y_transformed)*logits, dim=1) \r\n\r\n            # get the true label logit.\r\n            true_label = torch.masked_select(logits, y_transformed.bool()) \r\n            # print(\"largest\")\r\n            # print(largest)\r\n\r\n            # max among the difference between true label and second largest, and -tao\r\n            loss = -torch.clamp((true_label-second_largest),min=-t).sum()\r\n            \r\n            return loss\r\n        ### Your code ends\r\n\r\n    def perturb(self, model: nn.Module, X, y):\r\n        delta = torch.zeros_like(X)\r\n        \r\n        ### Your code here\r\n        \r\n        loss_fn = self.loss_func\r\n        X.requires_grad = True\r\n        # print(X.shape)\r\n        # gradient descent for the specified steps \r\n        for i in range(self.attack_step):\r\n            model.zero_grad()\r\n            logits = model(X + delta)\r\n            # print(logits)\r\n            # print(logits.shape)\r\n            # print(y.shape)\r\n            # print(y)\r\n            # loss = torch.nn.functional.cross_entropy(logits, y)\r\n            loss = loss_fn(logits,y)\r\n\r\n            # get gradient\r\n            loss.backward()\r\n            # print(logits[:,0]*logits[:,0].shape)\r\n            #print(logits)\r\n\r\n            #descent using sign-based gradient descent\r\n            delta = delta + self.alpha*torch.sign(X.grad)\r\n            # projection step. For l infinity step, each pixel in delta hat is either unchanged if its absolute value is less than eps, or is equal to epsilon if it's positive, or is equal to negative epsilon if it's negative.\r\n            delta = torch.clamp(delta, min=-self.eps,max=self.eps)\r\n            X.grad.zero_()\r\n\r\n        #need to be a valid image\r\n        X_adv = delta+X\r\n        X_adv = torch.clamp(X_adv,min=0,max=1)\r\n        delta = X_adv-X\r\n        ### Your code ends\r\n        \r\n        return delta\r\n\r\n\r\n### FGSMAttack\r\n'''\r\nTechnically you can transform your PGDAttack to FGSM Attack by controling parameters like `attack_step`. \r\nIf you do that, you do not need to implement FGSM in this class.\r\n'''\r\nclass FGSMAttack():\r\n    def __init__(self, eps=8 / 255, loss_type='ce', targeted=True, num_classes=10):\r\n        pass\r\n\r\n    def perturb(self, model: nn.Module, X, y):\r\n        delta = torch.ones_like(X)\r\n        ### Your code here\r\n\r\n        ### Your code ends\r\n        return delta\n"})})}function p(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},8453:(e,t,r)=>{r.d(t,{R:()=>o,x:()=>l});var n=r(6540);const s={},a=n.createContext(s);function o(e){const t=n.useContext(a);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),n.createElement(a.Provider,{value:t},e.children)}}}]);